{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykrx import stock\n",
    "from newspaper import Article\n",
    "import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from konlpy.tag import Okt\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공공데이터포털 api 주소(Without param)\n",
    "url_stock = \"http://api.seibro.or.kr/openapi/service/StockSvc/getKDRSecnInfo\"  \n",
    "api_service_key_stock = [\n",
    "    \"RXhGWArdgsytKaKf0g%2FWxNuo27wXxg4iChLUs9ePc39VvneddFbQ9v9ZXCDWJkdFbhqCvbw9kdMGy%2F%2Bv3it50A%3D%3D\",\n",
    "    \"bqvyeN8k%2B8%2BfRLf7p4CNQsUIEL%2BRb4b2YR08MD10RDv3BxHugq6bR1wFEAo8hTau3XgiLcA7bEBoclnMdyBfNQ%3D%3D\",\n",
    "    \"zUgkw3obrruAXAW6kZrJnIpK8UUBIrwXrfroSgoDS7NUlSB%2BDz94OTIkkWeP0V%2BzOz81JVtW84bqh1y0HpzcUg%3D%3D\",\n",
    "    \"w9Ra19Zqn3%2BLgg2zHoRiZa8zZPdSCXSgFgrgFGUkaYqqQRD6BVKMsUgiRyJqeEuG1pQ86vSioq03IRarAve7sg%3D%3D\",\n",
    "]  # service api key\n",
    "\n",
    "# 종목 이름 가져오는 코드\n",
    "\n",
    "day = (datetime.datetime.now() - datetime.timedelta(days=3)).strftime(\"%Y%m%d\")\n",
    "def getStockCode():\n",
    "    \"\"\"\n",
    "    market: 상장구분 (11=유가증권, 12=코스닥, 13=K-OTC, 14=코넥스, 50=기타비상장)\n",
    "    \"\"\"\n",
    "    url = f\"https://api.odcloud.kr/api/GetStockSecuritiesInfoService/v1/getStockPriceInfo?\"\n",
    "    stock_code = 0\n",
    "    while True:\n",
    "        api_decode_key_stock = requests.utils.unquote(\n",
    "            api_service_key_stock[stock_code], encoding=\"utf-8\"\n",
    "        )\n",
    "\n",
    "        params = {\n",
    "            \"serviceKey\": api_decode_key_stock,\n",
    "            \"mrktCls\": \"KOSPI\",\n",
    "            \"numOfRows\": 1000,\n",
    "            \"beginBasDt\":day\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, params=params)\n",
    "        if(response.status_code != 200):\n",
    "            print(response.status_code)\n",
    "            stock_code += 1\n",
    "            continue\n",
    "        xml = BeautifulSoup(response.text, \"lxml\")\n",
    "        items = xml.find(\"items\")\n",
    "        item_list = []\n",
    "        for item in items:\n",
    "            try:\n",
    "                item_dict = {\n",
    "                    \"stockName\": item.find(\"itmsnm\").text.strip(),\n",
    "                    \"stockCode\": item.find(\"srtncd\").text.strip(),\n",
    "                    \"marketCap\": int(item.find(\"mrkttotamt\").text.strip()),\n",
    "                    \"date\": [],\n",
    "                }\n",
    "            except AttributeError:\n",
    "                continue\n",
    "            item_list.append(item_dict)\n",
    "\n",
    "        return item_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_list = getStockCode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "940\n"
     ]
    }
   ],
   "source": [
    "marketCapList = sorted(item_list, key=lambda k:k[\"marketCap\"], reverse=True)\n",
    "print(len(marketCapList))\n",
    "first = []\n",
    "last = []\n",
    "\n",
    "# 시가총액 상위 하위 뽑기, 개수는 조절\n",
    "\n",
    "for i in marketCapList[:200]:\n",
    "    first.append(i)\n",
    "    \n",
    "for i in marketCapList[-200:]:\n",
    "    last.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = stock.get_market_ohlcv(\"20180101\", \"20201231\", i[\"stockCode\"], adjusted=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:32<00:00,  1.31it/s]\n",
      "100%|██████████| 200/200 [02:27<00:00,  1.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# 시가총액 상위는 등락률 10%, 하위는 20%로 조정하고 날짜 뽑기, 개수는 조절\n",
    "\n",
    "for i in tqdm(first):\n",
    "    df = stock.get_market_ohlcv(\"20200101\", \"20220506\", i[\"stockCode\"], adjusted=False)\n",
    "    cond = df[\"등락률\"] < -10\n",
    "    for j in df[cond].iloc:\n",
    "        i[\"date\"].append(j.name.strftime(\"%Y.%m.%d\"))\n",
    "        \n",
    "for i in tqdm(last):\n",
    "    df = stock.get_market_ohlcv(\"20200101\", \"20220506\", i[\"stockCode\"], adjusted=False)\n",
    "    cond = df[\"등락률\"] < -20\n",
    "    for j in df[cond].iloc:\n",
    "        i[\"date\"].append(j.name.strftime(\"%Y.%m.%d\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#각 크롤링 결과 저장하기 위한 리스트 선언 \n",
    "title_text=[]\n",
    "link_text=[]\n",
    "source_text=[]\n",
    "date_text=[]\n",
    "contents_text=[]\n",
    "result_news = []\n",
    "\n",
    "#엑셀로 저장하기 위한 변수\n",
    "RESULT_PATH ='\"/Users/bumseok/workspace/capstone-2022-07/model\"'  #결과 저장할 경로\n",
    "now = datetime.datetime.now() #파일이름 현 시간으로 저장하기\n",
    "\n",
    "headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36'}\n",
    "\n",
    "\n",
    "#날짜 정제화 함수\n",
    "def date_cleansing(test):\n",
    "    try:\n",
    "        #지난 뉴스\n",
    "        #머니투데이  10면1단  2018.11.05.  네이버뉴스   보내기  \n",
    "        pattern = '\\d+.(\\d+).(\\d+).'  #정규표현식 \n",
    "    \n",
    "        r = re.compile(pattern)\n",
    "        match = r.search(test).group(0)  # 2018.11.05.\n",
    "        date_text.append(match)\n",
    "        \n",
    "    except AttributeError:\n",
    "        #최근 뉴스\n",
    "        #이데일리  1시간 전  네이버뉴스   보내기  \n",
    "        pattern = '\\w* (\\d\\w*)'     #정규표현식 \n",
    "        \n",
    "        r = re.compile(pattern)\n",
    "        match = r.search(test).group(1)\n",
    "        #print(match)\n",
    "        date_text.append(match)\n",
    "\n",
    "\n",
    "#내용 정제화 함수 \n",
    "def contents_cleansing(contents):\n",
    "    first_cleansing_contents = re.sub('<dl>.*?</a> </div> </dd> <dd>', '', \n",
    "                                      str(contents)).strip()  #앞에 필요없는 부분 제거\n",
    "    second_cleansing_contents = re.sub('<ul class=\"relation_lst\">.*?</dd>', '', \n",
    "                                       first_cleansing_contents).strip()#뒤에 필요없는 부분 제거 (새끼 기사)\n",
    "    third_cleansing_contents = re.sub('<.+?>', '', second_cleansing_contents).strip()\n",
    "    contents_text.append(third_cleansing_contents)\n",
    "    #print(contents_text)\n",
    "    \n",
    "        \n",
    "def crawler(maxpage,query,sort,s_date,e_date):\n",
    "    \n",
    "    s_from = s_date.replace(\".\",\"\")\n",
    "    e_to = e_date.replace(\".\",\"\")\n",
    "    page = 1  \n",
    "    maxpage_t =(int(maxpage)-1)*10+1   # 11= 2페이지 21=3페이지 31=4페이지  ...81=9페이지 , 91=10페이지, 101=11페이지\n",
    "    result = {}\n",
    "    \n",
    "    while page <= maxpage_t:\n",
    "        url = \"https://search.naver.com/search.naver?where=news&sm=tab_pge&query=\" + query + \"&sort=\"+sort+\"&ds=\" + s_date + \"&de=\" + e_date + \"&nso=so%3Ar%2Cp%3Afrom\" + s_from + \"to\" + e_to + \"%2Ca%3A&start=\" + str(page)\n",
    "        \n",
    "        response = requests.get(url, headers=headers)\n",
    "        html = response.text\n",
    " \n",
    "        #뷰티풀소프의 인자값 지정\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    " \n",
    "        #<a>태그에서 제목과 링크주소 추출\n",
    "        atags = soup.select('.news_tit')\n",
    "        for atag in atags:\n",
    "            link_text.append(atag['href'])   #링크주소\n",
    "        \n",
    "        page += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [10:57<00:00,  3.29s/it]\n",
      "100%|██████████| 200/200 [09:52<00:00,  2.96s/it]\n"
     ]
    }
   ],
   "source": [
    "# 크롤러 실행 코드, 크롤링 페이지 조절\n",
    "\n",
    "for i in tqdm(first):\n",
    "    if len(i[\"date\"]) == 0:\n",
    "        continue\n",
    "    for j in i[\"date\"]:\n",
    "        crawler(3, i[\"stockName\"], \"0\", j, j)\n",
    "\n",
    "        \n",
    "for i in tqdm(last):\n",
    "    if len(i[\"date\"]) == 0:\n",
    "        continue\n",
    "    for j in i[\"date\"]:\n",
    "        crawler(3, i[\"stockName\"], \"0\", j, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38105\n"
     ]
    }
   ],
   "source": [
    "print(len(link_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_df = pd.DataFrame(link_text)\n",
    "link_df.to_csv(\"plusnews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 198/38105 [00:30<1:34:13,  6.71it/s]WARNING:urllib3.connectionpool:Failed to parse headers (url=https://www.yakup.com:443/news/index.html?mode=view&cat=12&nid=242931): [MissingHeaderBodySeparatorDefect()], unparsed data: 'P3P : CP=\"ALL CURa ADMa DEVa TAIa OUR BUS IND PHY ONL UNI PUR FIN COM NAV INT DEM CNT STA POL HEA PRE LOC OTC\"\\r\\nExpires: Thu, 19 Nov 1981 08:52:00 GMT\\r\\nLast-Modified: Mon, 09 May 2022 14:55:10 GMT\\r\\nCache-Control: no-store, no-cache, must-revalidate\\r\\nPragma: no-cache\\r\\nSet-Cookie: PHPSESSID=ciir12p0ee2ma8m93f00atkhg5; path=/\\r\\nSet-Cookie: df_count_flag=1; path=/\\r\\nVary: Accept-Encoding,User-Agent\\r\\nContent-Encoding: gzip\\r\\nContent-Length: 19070\\r\\nKeep-Alive: timeout=5, max=100\\r\\nConnection: Keep-Alive\\r\\nContent-Type: text/html; charset=UTF-8\\r\\n\\r\\n'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 469, in _make_request\n",
      "    assert_header_parsing(httplib_response.msg)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/urllib3/util/response.py\", line 91, in assert_header_parsing\n",
      "    raise HeaderParsingError(defects=defects, unparsed_data=unparsed_data)\n",
      "urllib3.exceptions.HeaderParsingError: [MissingHeaderBodySeparatorDefect()], unparsed data: 'P3P : CP=\"ALL CURa ADMa DEVa TAIa OUR BUS IND PHY ONL UNI PUR FIN COM NAV INT DEM CNT STA POL HEA PRE LOC OTC\"\\r\\nExpires: Thu, 19 Nov 1981 08:52:00 GMT\\r\\nLast-Modified: Mon, 09 May 2022 14:55:10 GMT\\r\\nCache-Control: no-store, no-cache, must-revalidate\\r\\nPragma: no-cache\\r\\nSet-Cookie: PHPSESSID=ciir12p0ee2ma8m93f00atkhg5; path=/\\r\\nSet-Cookie: df_count_flag=1; path=/\\r\\nVary: Accept-Encoding,User-Agent\\r\\nContent-Encoding: gzip\\r\\nContent-Length: 19070\\r\\nKeep-Alive: timeout=5, max=100\\r\\nConnection: Keep-Alive\\r\\nContent-Type: text/html; charset=UTF-8\\r\\n\\r\\n'\n",
      "  3%|▎         | 980/38105 [02:14<1:25:06,  7.27it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/pool.py:853\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/pool.py?line=851'>852</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/pool.py?line=852'>853</a>\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_items\u001b[39m.\u001b[39;49mpopleft()\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/pool.py?line=853'>854</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/lwh/WORKSPACE/capstone-2022-07/model/tf-idf/get_train_news.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lwh/WORKSPACE/capstone-2022-07/model/tf-idf/get_train_news.ipynb#ch0000008?line=13'>14</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lwh/WORKSPACE/capstone-2022-07/model/tf-idf/get_train_news.ipynb#ch0000008?line=16'>17</a>\u001b[0m pool \u001b[39m=\u001b[39m ThreadPool(\u001b[39m10\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lwh/WORKSPACE/capstone-2022-07/model/tf-idf/get_train_news.ipynb#ch0000008?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m tqdm(pool\u001b[39m.\u001b[39mimap_unordered(getNews, link_text), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(link_text)):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lwh/WORKSPACE/capstone-2022-07/model/tf-idf/get_train_news.ipynb#ch0000008?line=19'>20</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lwh/WORKSPACE/capstone-2022-07/model/tf-idf/get_train_news.ipynb#ch0000008?line=21'>22</a>\u001b[0m pool\u001b[39m.\u001b[39mclose() \n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/std.py?line=1191'>1192</a>\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/std.py?line=1193'>1194</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/std.py?line=1194'>1195</a>\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/std.py?line=1195'>1196</a>\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/std.py?line=1196'>1197</a>\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/std.py?line=1197'>1198</a>\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/pool.py:858\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/pool.py?line=855'>856</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/pool.py?line=856'>857</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/pool.py?line=857'>858</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/pool.py?line=858'>859</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/pool.py?line=859'>860</a>\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items\u001b[39m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py?line=317'>318</a>\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py?line=318'>319</a>\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py?line=319'>320</a>\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py?line=320'>321</a>\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py?line=321'>322</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 뉴스 상세 정보 가져오기\n",
    "\n",
    "news_list = []\n",
    "\n",
    "def getNews(url):\n",
    "    article = Article(url, encoding=\"CP949\")\n",
    "    article.download()\n",
    "    try:\n",
    "        article.parse()\n",
    "        if article.text == \"\" or article.title == \"\" or article.publish_date is None or article.url == \"\":\n",
    "            return\n",
    "        news_list.append({\"title\": article.title, \"content\": article.text, \"time\": article.publish_date.strftime(\"%Y-%m-%d\"), \"url\": article.url})\n",
    "    except:\n",
    "        return\n",
    "    \n",
    "            \n",
    "pool = ThreadPool(10)\n",
    "\n",
    "for _ in tqdm(pool.imap_unordered(getNews, link_text), total=len(link_text)):\n",
    "    pass\n",
    "\n",
    "pool.close() \n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 csv -> 엑셀 실행 후 데이터 탭 -> 데이터 가져오기 -> 텍스트/CSV -> 유니코드 실행 후 엑셀 저장\n",
    "\n",
    "link_df = pd.DataFrame(news_list, columns=[\"title\", \"content\", \"date\", \"url\"])\n",
    "link_df.to_csv(\"plusnews.csv\")\n",
    "\n",
    "# 엑셀 저장까지 했으면 밑에서부터 수정 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
